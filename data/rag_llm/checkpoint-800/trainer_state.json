{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.8283185840707965,
  "eval_steps": 500,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07079646017699115,
      "grad_norm": 0.8735554218292236,
      "learning_rate": 0.0001955241460541814,
      "loss": 1.2409,
      "step": 20
    },
    {
      "epoch": 0.1415929203539823,
      "grad_norm": 0.4767307937145233,
      "learning_rate": 0.00019081272084805654,
      "loss": 0.3163,
      "step": 40
    },
    {
      "epoch": 0.21238938053097345,
      "grad_norm": 0.452033132314682,
      "learning_rate": 0.00018610129564193168,
      "loss": 0.2164,
      "step": 60
    },
    {
      "epoch": 0.2831858407079646,
      "grad_norm": 0.4059810936450958,
      "learning_rate": 0.00018138987043580685,
      "loss": 0.1908,
      "step": 80
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.3263070285320282,
      "learning_rate": 0.00017667844522968197,
      "loss": 0.1848,
      "step": 100
    },
    {
      "epoch": 0.4247787610619469,
      "grad_norm": 0.39828169345855713,
      "learning_rate": 0.00017196702002355714,
      "loss": 0.1792,
      "step": 120
    },
    {
      "epoch": 0.49557522123893805,
      "grad_norm": 0.34969329833984375,
      "learning_rate": 0.00016725559481743226,
      "loss": 0.169,
      "step": 140
    },
    {
      "epoch": 0.5663716814159292,
      "grad_norm": 0.38346973061561584,
      "learning_rate": 0.00016254416961130743,
      "loss": 0.1614,
      "step": 160
    },
    {
      "epoch": 0.6371681415929203,
      "grad_norm": 0.36072272062301636,
      "learning_rate": 0.00015783274440518257,
      "loss": 0.1578,
      "step": 180
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 0.45759376883506775,
      "learning_rate": 0.00015312131919905772,
      "loss": 0.1501,
      "step": 200
    },
    {
      "epoch": 0.7787610619469026,
      "grad_norm": 0.3738437294960022,
      "learning_rate": 0.00014840989399293289,
      "loss": 0.137,
      "step": 220
    },
    {
      "epoch": 0.8495575221238938,
      "grad_norm": 0.3162771463394165,
      "learning_rate": 0.000143698468786808,
      "loss": 0.1267,
      "step": 240
    },
    {
      "epoch": 0.9203539823008849,
      "grad_norm": 0.3327897787094116,
      "learning_rate": 0.00013898704358068317,
      "loss": 0.1259,
      "step": 260
    },
    {
      "epoch": 0.9911504424778761,
      "grad_norm": 0.42591702938079834,
      "learning_rate": 0.00013427561837455832,
      "loss": 0.1211,
      "step": 280
    },
    {
      "epoch": 1.0601769911504424,
      "grad_norm": 0.5732926726341248,
      "learning_rate": 0.00012956419316843346,
      "loss": 0.1178,
      "step": 300
    },
    {
      "epoch": 1.1309734513274337,
      "grad_norm": 0.4385354518890381,
      "learning_rate": 0.0001248527679623086,
      "loss": 0.1058,
      "step": 320
    },
    {
      "epoch": 1.2017699115044247,
      "grad_norm": 0.47225573658943176,
      "learning_rate": 0.00012014134275618376,
      "loss": 0.104,
      "step": 340
    },
    {
      "epoch": 1.272566371681416,
      "grad_norm": 0.41262727975845337,
      "learning_rate": 0.00011542991755005889,
      "loss": 0.0977,
      "step": 360
    },
    {
      "epoch": 1.343362831858407,
      "grad_norm": 0.38039883971214294,
      "learning_rate": 0.00011071849234393406,
      "loss": 0.0928,
      "step": 380
    },
    {
      "epoch": 1.4141592920353983,
      "grad_norm": 0.3993365168571472,
      "learning_rate": 0.00010600706713780919,
      "loss": 0.0859,
      "step": 400
    },
    {
      "epoch": 1.4849557522123895,
      "grad_norm": 0.8536728024482727,
      "learning_rate": 0.00010129564193168435,
      "loss": 0.0872,
      "step": 420
    },
    {
      "epoch": 1.5557522123893806,
      "grad_norm": 0.5433493256568909,
      "learning_rate": 9.658421672555948e-05,
      "loss": 0.0766,
      "step": 440
    },
    {
      "epoch": 1.6265486725663716,
      "grad_norm": 0.4361859858036041,
      "learning_rate": 9.187279151943463e-05,
      "loss": 0.0706,
      "step": 460
    },
    {
      "epoch": 1.6973451327433628,
      "grad_norm": 0.43221497535705566,
      "learning_rate": 8.716136631330978e-05,
      "loss": 0.0649,
      "step": 480
    },
    {
      "epoch": 1.768141592920354,
      "grad_norm": 0.5130404829978943,
      "learning_rate": 8.244994110718492e-05,
      "loss": 0.0594,
      "step": 500
    },
    {
      "epoch": 1.8389380530973451,
      "grad_norm": 0.6705392003059387,
      "learning_rate": 7.773851590106007e-05,
      "loss": 0.064,
      "step": 520
    },
    {
      "epoch": 1.9097345132743362,
      "grad_norm": 0.27091777324676514,
      "learning_rate": 7.302709069493522e-05,
      "loss": 0.0531,
      "step": 540
    },
    {
      "epoch": 1.9805309734513274,
      "grad_norm": 0.32072705030441284,
      "learning_rate": 6.831566548881037e-05,
      "loss": 0.0516,
      "step": 560
    },
    {
      "epoch": 2.049557522123894,
      "grad_norm": 0.25150859355926514,
      "learning_rate": 6.360424028268551e-05,
      "loss": 0.0466,
      "step": 580
    },
    {
      "epoch": 2.120353982300885,
      "grad_norm": 0.365321546792984,
      "learning_rate": 5.889281507656066e-05,
      "loss": 0.0431,
      "step": 600
    },
    {
      "epoch": 2.191150442477876,
      "grad_norm": 0.19953466951847076,
      "learning_rate": 5.41813898704358e-05,
      "loss": 0.0418,
      "step": 620
    },
    {
      "epoch": 2.2619469026548673,
      "grad_norm": 0.2647723853588104,
      "learning_rate": 4.946996466431096e-05,
      "loss": 0.0394,
      "step": 640
    },
    {
      "epoch": 2.3327433628318586,
      "grad_norm": 0.17902079224586487,
      "learning_rate": 4.47585394581861e-05,
      "loss": 0.0379,
      "step": 660
    },
    {
      "epoch": 2.4035398230088494,
      "grad_norm": 0.4096084237098694,
      "learning_rate": 4.0047114252061253e-05,
      "loss": 0.0385,
      "step": 680
    },
    {
      "epoch": 2.4743362831858406,
      "grad_norm": 0.20656445622444153,
      "learning_rate": 3.53356890459364e-05,
      "loss": 0.0371,
      "step": 700
    },
    {
      "epoch": 2.545132743362832,
      "grad_norm": 0.21117927134037018,
      "learning_rate": 3.062426383981155e-05,
      "loss": 0.0361,
      "step": 720
    },
    {
      "epoch": 2.615929203539823,
      "grad_norm": 0.1860218048095703,
      "learning_rate": 2.5912838633686694e-05,
      "loss": 0.0379,
      "step": 740
    },
    {
      "epoch": 2.686725663716814,
      "grad_norm": 0.24609486758708954,
      "learning_rate": 2.120141342756184e-05,
      "loss": 0.0377,
      "step": 760
    },
    {
      "epoch": 2.7575221238938052,
      "grad_norm": 0.16991785168647766,
      "learning_rate": 1.6489988221436988e-05,
      "loss": 0.0362,
      "step": 780
    },
    {
      "epoch": 2.8283185840707965,
      "grad_norm": 0.18205320835113525,
      "learning_rate": 1.1778563015312133e-05,
      "loss": 0.035,
      "step": 800
    }
  ],
  "logging_steps": 20,
  "max_steps": 849,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2990799987448218e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
